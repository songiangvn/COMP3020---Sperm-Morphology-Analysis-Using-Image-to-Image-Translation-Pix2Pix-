{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asnolvupcUnM"
   },
   "source": [
    "#**Tutorial:** Ensembled Deep Learning for the Classification of Human Sperm Head Morphology - 3x 5-fold CV w/ SCIAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXF3SnVNnQD2"
   },
   "source": [
    "This notebook will fit all models associated with the 3x 5-fold CV process using the SCIAN dataset for given hyperparameters.\n",
    "\n",
    "Many functions/classes are used to steamline the code.\n",
    "\n",
    "The base-model fitting section can be stopped at any point and will resume from that point when restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnUBHpp4BjhM"
   },
   "source": [
    "## ***Setting up***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:39.633500Z",
     "iopub.status.busy": "2026-01-14T13:52:39.633240Z",
     "iopub.status.idle": "2026-01-14T13:52:48.893048Z",
     "shell.execute_reply": "2026-01-14T13:52:48.892489Z",
     "shell.execute_reply.started": "2026-01-14T13:52:39.633470Z"
    },
    "id": "aN0t_JycfSut",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import torch # PyTorch\n",
    "import torch.nn as nn # For convenience when defining a model\n",
    "import torchvision # To access pre-trained deep learning models\n",
    "import torchvision.transforms as transforms # For applying pre-processing and data augmentation to the image data\n",
    "from torchvision.datasets import ImageFolder # For defining the storage location of image data\n",
    "from torch.utils.data import TensorDataset # PyTorch uses datasets comprised of tensors\n",
    "from torch.utils.data.dataloader import DataLoader # For loading mini-batches during training process\n",
    "from torch.utils.data import random_split, Dataset, Subset, WeightedRandomSampler # For generating a random split between the training and testing data,\n",
    "#   For creating a dataset object (I think), For taking a subset of a dataset.\n",
    "\n",
    "\n",
    "import numpy as np # For manipulating arrays and other python object types. 'np' is standard shorthand.\n",
    "import pandas as pd # For manipulating dataframes. 'pd' is standard shorthand.\n",
    "from collections import Counter # To count images in each class\n",
    "import matplotlib.pyplot as plt\n",
    "import math # Some basic mathematic functions\n",
    "import warnings # For checking this a working as expected\n",
    "import sklearn\n",
    "import sklearn.metrics # For easy calculation of performance metrics\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_K90AqqEo9QB"
   },
   "source": [
    "##***Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.894214Z",
     "iopub.status.busy": "2026-01-14T13:52:48.893860Z",
     "iopub.status.idle": "2026-01-14T13:52:48.899025Z",
     "shell.execute_reply": "2026-01-14T13:52:48.898388Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.894179Z"
    },
    "id": "5dIidbiElNSZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def foldSizes(dataset, k):\n",
    "  \"\"\"\n",
    "  Takes the dataset and the number of desired folds and determines the number of examples in each fold\n",
    "  \"\"\"\n",
    "  fold_base_size = math.floor(len(dataset)/k) # the minimum size of a fold.\n",
    "  fold_sizes = [fold_base_size]*5 # a list containing the sizes of each fold\n",
    "  # Calculating the un-allocated images\n",
    "  remaining_count = len(dataset) % k\n",
    "  # Distributing the un-allocated images across the folds\n",
    "  for i in range(remaining_count):\n",
    "    fold_sizes[i] += 1\n",
    "\n",
    "  # Checking all images are allocated\n",
    "  if sum(fold_sizes) != len(dataset):\n",
    "    warnings.warn(\"Not all iamges are allocated to folds\")\n",
    "\n",
    "  return fold_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.900713Z",
     "iopub.status.busy": "2026-01-14T13:52:48.900421Z",
     "iopub.status.idle": "2026-01-14T13:52:48.932517Z",
     "shell.execute_reply": "2026-01-14T13:52:48.931982Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.900686Z"
    },
    "id": "ZXJwVQRk8XZk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def allFoldsTrainTestIndices(seed, dataset, fold_sizes):\n",
    "  \"\"\"\n",
    "  Outputs a list containing the train and test set indices for each of the k-folds, given a random seed.\n",
    "  This can be used for completing the 1x 5-fold CV in parts rather than all at once.\n",
    "  \"\"\"\n",
    "  # Set seed for random split\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  # Create the indices for each fold\n",
    "  folds = torch.utils.data.random_split(dataset, fold_sizes)\n",
    "  # Extracting indices\n",
    "  fold_indices = []\n",
    "  for fold in folds:\n",
    "    fold_indices.append(fold.indices)\n",
    "\n",
    "  # Creating train and test sets (ie. combining indices) for each fold\n",
    "\n",
    "  train_test_idx_folds = [] # Storage containing train and test indices for all folds\n",
    "\n",
    "  for fold in range(len(fold_sizes)): # len(fold_sizes) is effectively 'k'\n",
    "    train_idx = [] # Storage\n",
    "    test_idx = []  # Storage\n",
    "    train_test_idx_fold = [] # Storage for both the above lists\n",
    "\n",
    "    # Using respective folds to create train and test sets\n",
    "    for i in range(k):\n",
    "      if i == fold:\n",
    "        test_idx = fold_indices[i]\n",
    "      else:\n",
    "        train_idx = train_idx + fold_indices[i]\n",
    "\n",
    "      # Checking that there is no overlap\n",
    "    if len(set(train_idx).intersection(test_idx)): # If there is any overlap between the training and testing sets\n",
    "      warnings.warn(\"Train and test set images are not mutually exclusive\")\n",
    "\n",
    "    # Making a list of lists containing train indicies and test indices\n",
    "    train_test_idx_fold.append(train_idx)\n",
    "    train_test_idx_fold.append(test_idx)\n",
    "\n",
    "    # Append train and test indices for this fold to a list containing this for all folds\n",
    "    train_test_idx_folds.append(train_test_idx_fold)\n",
    "  return train_test_idx_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.933416Z",
     "iopub.status.busy": "2026-01-14T13:52:48.933196Z",
     "iopub.status.idle": "2026-01-14T13:52:48.948170Z",
     "shell.execute_reply": "2026-01-14T13:52:48.947626Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.933396Z"
    },
    "id": "rGOp5bTjDAXC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def trainBaseModel(model, num_epochs, learn_rate, dl_train, dl_test,\n",
    "                   patience=10, min_delta=1e-4, model_save_path='./model.pth'):\n",
    "  \"\"\"\n",
    "  Training loop with early stopping based on F1-score.\n",
    "  NOTE: Early stopping is performed on test data (not ideal).\n",
    "  Modified to work with local filesystem.\n",
    "  \"\"\"\n",
    "\n",
    "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "  model.to(device)\n",
    "\n",
    "  best_f1 = 0\n",
    "  best_acc = 0\n",
    "  best_re = 0\n",
    "  best_pr = 0\n",
    "  best_epoch = 0\n",
    "\n",
    "  f1_scores = []\n",
    "  epochs_no_improve = 0\n",
    "\n",
    "  optimizer = torch.optim.Adam(params=model.parameters(), lr=learn_rate)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    # -----------------------\n",
    "    # TRAIN\n",
    "    # -----------------------\n",
    "    model.train()\n",
    "    for images, labels in dl_train:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # -----------------------\n",
    "    # EVALUATE\n",
    "    # -----------------------\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for images, labels in dl_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds += predicted.tolist()\n",
    "        test_labels += labels.tolist()\n",
    "\n",
    "    test_preds = torch.tensor(test_preds).cpu()\n",
    "    test_labels = torch.tensor(test_labels).cpu()\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_labels, test_preds)\n",
    "    recall = sklearn.metrics.recall_score(test_labels, test_preds, average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(test_labels, test_preds, average=\"macro\")\n",
    "    f1_score = sklearn.metrics.f1_score(test_labels, test_preds, average=\"macro\")\n",
    "\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "    # -----------------------\n",
    "    # EARLY STOPPING CHECK\n",
    "    # -----------------------\n",
    "    if f1_score > best_f1 + min_delta:\n",
    "      best_f1 = f1_score\n",
    "      best_acc = accuracy\n",
    "      best_re = recall\n",
    "      best_pr = precision\n",
    "      best_epoch = epoch\n",
    "      epochs_no_improve = 0\n",
    "\n",
    "      torch.save(model, model_save_path)\n",
    "\n",
    "    else:\n",
    "      epochs_no_improve += 1\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch [{epoch+1}/{num_epochs}] | F1: {f1_score:.4f}\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "      print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "      break\n",
    "\n",
    "  # -----------------------\n",
    "  # RESULTS\n",
    "  # -----------------------\n",
    "  print('Results:\\n \\\n",
    "  Accuracy  = {:.3f}% \\n \\\n",
    "  Recall    = {:.3f}% \\n \\\n",
    "  Precision = {:.3f}% \\n \\\n",
    "  F1 Score  = {:.3f}% \\n \\\n",
    "  Best Epoch = {}'.format(\n",
    "      best_acc, best_re, best_pr, best_f1, best_epoch + 1\n",
    "  ))\n",
    "\n",
    "  plt.plot(f1_scores)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"F1-score\")\n",
    "  plt.show()\n",
    "\n",
    "  return best_acc, best_re, best_pr, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.949170Z",
     "iopub.status.busy": "2026-01-14T13:52:48.948935Z",
     "iopub.status.idle": "2026-01-14T13:52:48.968178Z",
     "shell.execute_reply": "2026-01-14T13:52:48.967603Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.949150Z"
    },
    "id": "UcyauXfKbY4o",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def trainMetaClassifier(model, num_epochs, learn_rate, momentum, weight_decay,\n",
    "                        dl_train, dl_test, patience=10, min_delta=1e-4, model_save_path='./model.pth'):\n",
    "  \"\"\"\n",
    "  Training loop for the Meta-Classifier with early stopping.\n",
    "  NOTE: Early stopping is performed on test data (not ideal).\n",
    "  Modified to work with local filesystem.\n",
    "  \"\"\"\n",
    "\n",
    "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "  model.to(device)\n",
    "\n",
    "  best_f1 = 0\n",
    "  best_acc = 0\n",
    "  best_re = 0\n",
    "  best_pr = 0\n",
    "  best_epoch = 0\n",
    "\n",
    "  epochs_no_improve = 0\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "      params=model.parameters(),\n",
    "      lr=learn_rate,\n",
    "      momentum=momentum,\n",
    "      weight_decay=weight_decay\n",
    "  )\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    # -----------------------\n",
    "    # TRAIN\n",
    "    # -----------------------\n",
    "    model.train()\n",
    "    for inputs, labels in dl_train:\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # -----------------------\n",
    "    # EVALUATE\n",
    "    # -----------------------\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in dl_test:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds += predicted.tolist()\n",
    "        test_labels += labels.tolist()\n",
    "\n",
    "    test_preds = torch.tensor(test_preds).cpu()\n",
    "    test_labels = torch.tensor(test_labels).cpu()\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_labels, test_preds)\n",
    "    recall = sklearn.metrics.recall_score(test_labels, test_preds, average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(test_labels, test_preds, average=\"macro\")\n",
    "    f1_score = sklearn.metrics.f1_score(test_labels, test_preds, average=\"macro\")\n",
    "\n",
    "    # -----------------------\n",
    "    # EARLY STOPPING CHECK\n",
    "    # -----------------------\n",
    "    if f1_score > best_f1 + min_delta:\n",
    "      best_f1 = f1_score\n",
    "      best_acc = accuracy\n",
    "      best_re = recall\n",
    "      best_pr = precision\n",
    "      best_epoch = epoch\n",
    "      epochs_no_improve = 0\n",
    "\n",
    "      torch.save(model, model_save_path)\n",
    "\n",
    "    else:\n",
    "      epochs_no_improve += 1\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch [{epoch+1}/{num_epochs}] | F1: {f1_score:.4f}\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "      print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "      break\n",
    "\n",
    "  # -----------------------\n",
    "  # RESULTS\n",
    "  # -----------------------\n",
    "  print('Results:\\n \\\n",
    "  Accuracy  = {:.3f}% \\n \\\n",
    "  Recall    = {:.3f}% \\n \\\n",
    "  Precision = {:.3f}% \\n \\\n",
    "  F1 Score  = {:.3f}% \\n \\\n",
    "  Best Epoch = {}'.format(\n",
    "      best_acc, best_re, best_pr, best_f1, best_epoch + 1\n",
    "  ))\n",
    "\n",
    "  return best_acc, best_re, best_pr, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.969179Z",
     "iopub.status.busy": "2026-01-14T13:52:48.968921Z",
     "iopub.status.idle": "2026-01-14T13:52:48.985646Z",
     "shell.execute_reply": "2026-01-14T13:52:48.985072Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.969158Z"
    },
    "id": "FcB_H9O_OnIn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "  # Softmax function\n",
    "  def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:48.986547Z",
     "iopub.status.busy": "2026-01-14T13:52:48.986280Z",
     "iopub.status.idle": "2026-01-14T13:52:49.003951Z",
     "shell.execute_reply": "2026-01-14T13:52:49.003358Z",
     "shell.execute_reply.started": "2026-01-14T13:52:48.986507Z"
    },
    "id": "y23xTOOA8793",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions using the trained model\n",
    "def generateCNNPredictions(data_path, transformations, train_test_idx, batch_size, seed, device='cuda:0', model_save_path='./model.pth'):\n",
    "  \"\"\"\n",
    "  This function produces predictions for a single fold using the trained model saved to the temporary location.\n",
    "  These will form part of the train and test sets for the meta-classifier.\n",
    "  Modified for 2 classes.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load the data with test set transformations applied (ie. no data augmentation)\n",
    "  dataset = ImageFolder(data_path, transform=transformations)\n",
    "  train_test_idx[0].sort() # Sorting in place, not required.\n",
    "  train_test_idx[1].sort() # ^\n",
    "  ds_train = Subset(dataset, indices=train_test_idx[0])\n",
    "  ds_test = Subset(dataset, indices=train_test_idx[1])\n",
    "\n",
    "  # We need to redefine the train set sampler to ensure all base-models predict on the data in the same order\n",
    "  labels_train = [dataset.targets[i] for i in train_test_idx[0]]\n",
    "  counts = dict(Counter(labels_train))\n",
    "  counts = np.array(list(counts.values())) # converting counts to a numpy array\n",
    "  # Assigning a sampling weight to each class\n",
    "  weights = 1. / counts\n",
    "  # Getting weights for each image (ie. weight for the class that each image belongs to)\n",
    "  samples_weight = np.array([weights[t] for t in labels_train])\n",
    "  samples_weight = torch.from_numpy(samples_weight) # Converting to a tensor\n",
    "  samples_weight = samples_weight.double() # Converting elements to doubles for some reason\n",
    "  # Defining the sampler\n",
    "  g = torch.Generator()\n",
    "  g.manual_seed(seed)\n",
    "  sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True, generator=g)\n",
    "  # Now defining the dataloaders\n",
    "  dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=False, sampler=sampler)\n",
    "  dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    "  # Loading the model from save\n",
    "  model = torch.load(model_save_path, weights_only=False)\n",
    "  # Sending to device for faster computing\n",
    "  model.to(device)\n",
    "\n",
    "  # Generating predictions\n",
    "\n",
    "  # Train set\n",
    "  # Storage\n",
    "  preds_train = []\n",
    "  labels_train = []\n",
    "  model.eval() # Set model to evaluation mode, we aren't training so we want the best predictions possible\n",
    "  with torch.no_grad(): # As we aren't performing backprop, we don't need gradients\n",
    "    for i, (images, labels) in enumerate(dl_train):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      preds = model(images)\n",
    "      preds_train = preds_train + preds.tolist()\n",
    "      labels_train = labels_train + labels.tolist()\n",
    "\n",
    "  # Test set\n",
    "  # Storage\n",
    "  preds_test = []\n",
    "  labels_test = []\n",
    "  model.eval() # Set model to evaluation mode, we aren't training so we want the best predictions possible\n",
    "  with torch.no_grad(): # As we aren't performing backprop, we don't need gradients\n",
    "    for i, (images, labels) in enumerate(dl_test):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      preds = model(images)\n",
    "      preds_test = preds_test + preds.tolist()\n",
    "      labels_test = labels_test + labels.tolist()\n",
    "\n",
    "  # Converting to softmax\n",
    "  # Train\n",
    "  for i in range(len(preds_train)):\n",
    "    preds_train[i] = softmax(preds_train[i])\n",
    "  # Test\n",
    "  for i in range(len(preds_test)):\n",
    "    preds_test[i] = softmax(preds_test[i])\n",
    "\n",
    "  # Convert to dataframes for easier saving - Modified for 2 classes\n",
    "  df_train = pd.merge(pd.DataFrame(labels_train), pd.DataFrame(preds_train), left_index=True, right_index=True)\n",
    "  df_test = pd.merge(pd.DataFrame(labels_test), pd.DataFrame(preds_test), left_index=True, right_index=True)\n",
    "  # Adjusting column names - Modified for 2 classes\n",
    "  col_names = ['labels', '0', '1']\n",
    "  df_train.columns = col_names\n",
    "  df_test.columns = col_names\n",
    "\n",
    "  return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.004978Z",
     "iopub.status.busy": "2026-01-14T13:52:49.004655Z",
     "iopub.status.idle": "2026-01-14T13:52:49.021929Z",
     "shell.execute_reply": "2026-01-14T13:52:49.021406Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.004957Z"
    },
    "id": "t8SKsInq1E0G",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generateMCPredictions(dl_train, dl_test, batch_size, device='cuda:0', model_save_path='./model.pth'):\n",
    "  \"\"\"\n",
    "  Generates predictions using the trained and temporarily saved meta-classifier.\n",
    "  Modified for 2 classes.\n",
    "  \"\"\"\n",
    "    # Loading the model from save\n",
    "  model = torch.load(model_save_path, weights_only=False)\n",
    "  # Sending to device for faster computing\n",
    "  model.to(device)\n",
    "\n",
    "  # Generating predictions\n",
    "  #\n",
    "  # Train set\n",
    "  # Storage\n",
    "  preds_train = []\n",
    "  labels_train = []\n",
    "  model.eval() # Set model to evaluation mode, we aren't training so we want the best predictions possible\n",
    "  with torch.no_grad(): # As we aren't performing backprop, we don't need gradients\n",
    "    for i, (inputs, targets) in enumerate(dl_train):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      preds = model(inputs)\n",
    "      preds_train = preds_train + preds.tolist()\n",
    "      labels_train = labels_train + targets.tolist()\n",
    "\n",
    "  # Test set\n",
    "  # Storage\n",
    "  preds_test = []\n",
    "  labels_test = []\n",
    "  model.eval() # Set model to evaluation mode, we aren't training so we want the best predictions possible\n",
    "  with torch.no_grad(): # As we aren't performing backprop, we don't need gradients\n",
    "    for i, (inputs, targets) in enumerate(dl_test):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      preds = model(inputs)\n",
    "      preds_test = preds_test + preds.tolist()\n",
    "      labels_test = labels_test + targets.tolist()\n",
    "\n",
    "  # Converting to softmax\n",
    "  # Train\n",
    "  for i in range(len(preds_train)):\n",
    "    preds_train[i] = softmax(preds_train[i])\n",
    "  # Test\n",
    "  for i in range(len(preds_test)):\n",
    "    preds_test[i] = softmax(preds_test[i])\n",
    "\n",
    "  # Convert to dataframes for easier saving - Modified for 2 classes\n",
    "  df_train = pd.merge(pd.DataFrame(labels_train), pd.DataFrame(preds_train), left_index=True, right_index=True)\n",
    "  df_test = pd.merge(pd.DataFrame(labels_test), pd.DataFrame(preds_test), left_index=True, right_index=True)\n",
    "  # Adjusting column names - Modified for 2 classes\n",
    "  col_names = ['labels', '0', '1']\n",
    "  df_train.columns = col_names\n",
    "  df_test.columns = col_names\n",
    "\n",
    "  return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.024239Z",
     "iopub.status.busy": "2026-01-14T13:52:49.023922Z",
     "iopub.status.idle": "2026-01-14T13:52:49.038297Z",
     "shell.execute_reply": "2026-01-14T13:52:49.037732Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.024219Z"
    },
    "id": "bRDJ203rX4R_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identity class for modifying ResNet-34\n",
    "#   Setting any layer to this class will effectively remove the layer.\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.039300Z",
     "iopub.status.busy": "2026-01-14T13:52:49.039056Z",
     "iopub.status.idle": "2026-01-14T13:52:49.056251Z",
     "shell.execute_reply": "2026-01-14T13:52:49.055792Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.039280Z"
    },
    "id": "_iUPr1tygGs8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getModel(model_name):\n",
    "  \"\"\"\n",
    "  Loads and returns a pre-trained CNN\n",
    "  Modified for 2 classes (abnormal/normal)\n",
    "  \"\"\"\n",
    "  pretrained = True\n",
    "  num_classes = 2  # Changed from 5 to 2 classes\n",
    "\n",
    "  if model_name == 'vgg16':\n",
    "    model = torchvision.models.vgg16(pretrained=pretrained)\n",
    "    model.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "  elif model_name == 'vgg19':\n",
    "    model = torchvision.models.vgg19(pretrained=pretrained)\n",
    "    model.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "  elif model_name == 'resnet':\n",
    "    model = torchvision.models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=256, out_features=num_classes, bias=True)\n",
    "    model.layer4 = Identity()\n",
    "  elif model_name == 'densenet':\n",
    "    model = torchvision.models.densenet161(pretrained=pretrained)\n",
    "    model.classifier = nn.Linear(in_features=2208, out_features=num_classes, bias=True)\n",
    "\n",
    "  # Returning the required model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.057250Z",
     "iopub.status.busy": "2026-01-14T13:52:49.056996Z",
     "iopub.status.idle": "2026-01-14T13:52:49.072257Z",
     "shell.execute_reply": "2026-01-14T13:52:49.071719Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.057229Z"
    },
    "id": "wydGmNmfoFFJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_name_generator(cv_config, base_path='./cv_results'):\n",
    "    \"\"\"\n",
    "    Generates the path to save the generated predictions to.\n",
    "    Modified for local filesystem\n",
    "    \"\"\"\n",
    "    # cv_config is a dataframe row containing the info for the model fit that was just done\n",
    "    model_name, repeat, fold, = cv_config['model'], cv_config['repeat'], cv_config['fold']\n",
    "    \n",
    "    repeats = ['repeat_0/', 'repeat_1/', 'repeat_2/']\n",
    "    folds = ['fold_0/', 'fold_1/', 'fold_2/', 'fold_3/', 'fold_4/']\n",
    "    \n",
    "    repeat_dir = repeats[repeat]\n",
    "    fold_dir = folds[fold]\n",
    "    \n",
    "    train_path = os.path.join(base_path, repeat_dir, fold_dir, f'{model_name}_train.csv')\n",
    "    test_path = os.path.join(base_path, repeat_dir, fold_dir, f'{model_name}_test.csv')\n",
    "    \n",
    "    os.makedirs(os.path.dirname(train_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(test_path), exist_ok=True)\n",
    "    \n",
    "    return train_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.073297Z",
     "iopub.status.busy": "2026-01-14T13:52:49.072982Z",
     "iopub.status.idle": "2026-01-14T13:52:49.089144Z",
     "shell.execute_reply": "2026-01-14T13:52:49.088510Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.073263Z"
    },
    "id": "smmAlCRYtb6Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def MyDataset(path):\n",
    "  \"\"\"\n",
    "  For preparing meta-classifier input data to use with PyTorch.\n",
    "  \"\"\"\n",
    "  # Load dataframe from CSV file\n",
    "  df = pd.read_csv(path)\n",
    "  # Define inputs and outputs\n",
    "  df_inputs = df.iloc[:,1:] # Select all columns except first (labels col)\n",
    "  df_targets = df.iloc[:,0] # Select first column\n",
    "  # Performing a necessary conversion from dataframe object\n",
    "  inputs = torch.from_numpy(df_inputs.values)\n",
    "  targets = torch.from_numpy(df_targets.values)\n",
    "  # Converting to a dataset object\n",
    "  ds = TensorDataset(inputs.float(), targets)\n",
    "  # Return the final dataset object we wanted\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.090311Z",
     "iopub.status.busy": "2026-01-14T13:52:49.089907Z",
     "iopub.status.idle": "2026-01-14T13:52:49.104218Z",
     "shell.execute_reply": "2026-01-14T13:52:49.103665Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.090266Z"
    },
    "id": "OvdwnPlQyw-K",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The meta-classifier class\n",
    "class metaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(metaClassifier, self).__init__()\n",
    "      # Modified for 2 classes: 4 models √ó 2 class probabilities = 8 inputs\n",
    "      self.fc1 = nn.Linear(8, 16)  # Changed from 20 to 8 inputs\n",
    "      self.bn1 = nn.BatchNorm1d(16)  # Changed from 32 to 16\n",
    "      self.dropout1 = nn.Dropout(0.2)\n",
    "      self.fc2 = nn.Linear(16, 16)  # Changed from 32 to 16\n",
    "      self.bn2 = nn.BatchNorm1d(16)  # Changed from 32 to 16\n",
    "      self.dropout2 = nn.Dropout(0.2)\n",
    "      self.fc3 = nn.Linear(16, 2)  # Changed from 5 to 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Here we define how the data will pass through the layers\n",
    "      x = self.fc1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.dropout1(x)\n",
    "      x = self.fc2(x)\n",
    "      x = self.bn2(x)\n",
    "      x = self.dropout2(x)\n",
    "      out = self.fc3(x)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:52:49.105467Z",
     "iopub.status.busy": "2026-01-14T13:52:49.105005Z",
     "iopub.status.idle": "2026-01-14T13:52:49.121862Z",
     "shell.execute_reply": "2026-01-14T13:52:49.121166Z",
     "shell.execute_reply.started": "2026-01-14T13:52:49.105446Z"
    },
    "id": "L89BejrAqgR0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getSampler(subset_train):\n",
    "  \"\"\"Generates the weighted random sampler using the train subset as input\"\"\"\n",
    "  # Getting train set indices\n",
    "  # Getting labels after sorting indices so weights are applied correctly\n",
    "  subset_train.indices.sort()\n",
    "  labels_train = [subset_train.dataset.targets[i] for i in subset_train.indices]\n",
    "\n",
    "  # Counting\n",
    "  counts = dict(Counter(labels_train))\n",
    "  counts = np.array(list(counts.values())) # converting counts to a numpy array\n",
    "\n",
    "  # Assigning a sampling weight to each class\n",
    "  weights = 1. / counts\n",
    "\n",
    "  # Getting/assigning weights for each image (ie. weight for the class that each image belongs to)\n",
    "  samples_weight = np.array([weights[t] for t in labels_train])\n",
    "  samples_weight = torch.from_numpy(samples_weight) # Converting to a tensor\n",
    "  samples_weight = samples_weight.double() # Convrting elements to doubles for some reason\n",
    "\n",
    "  # Defining the sampler\n",
    "  sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "  return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5DiOOuGBxz9"
   },
   "source": [
    "## ***Base-Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T13:54:25.931537Z",
     "iopub.status.busy": "2026-01-14T13:54:25.931171Z",
     "iopub.status.idle": "2026-01-14T13:59:53.405056Z",
     "shell.execute_reply": "2026-01-14T13:59:53.404174Z",
     "shell.execute_reply.started": "2026-01-14T13:54:25.931504Z"
    },
    "id": "G_AopmiOHE9o",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# ========================================\n",
    "# DATA PREPARATION - Modified for LOCAL\n",
    "# ========================================\n",
    "\n",
    "# Defining the transformations\n",
    "transformations_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transformations_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ========================================\n",
    "# DATASET PATHS - Updated for unstained_stained\n",
    "# ========================================\n",
    "# Main stained dataset\n",
    "data_dir_stained = '/home/23giang.ns/ML_Project/virtual_stainning/unstained_stained_OLD_augmented_tuned'\n",
    "\n",
    "# Full agreement: high quality labels\n",
    "data_dir_full = os.path.join(data_dir_stained, 'full_agreement')\n",
    "\n",
    "# ========================================\n",
    "# LOADING DATASETS - ONLY rotated_abnormal and rotated_normal folders\n",
    "# ========================================\n",
    "# Load rotated versions (augmented data)\n",
    "data_dir_abnormal = os.path.join(data_dir_full, 'rotated_abnormal')\n",
    "data_dir_normal = os.path.join(data_dir_full, 'rotated_normal')\n",
    "\n",
    "print(\"üìÇ Dataset Structure:\")\n",
    "print(f\"Loading rotated folders:\")\n",
    "print(f\"  - rotated_abnormal: {data_dir_abnormal}\")\n",
    "print(f\"  - rotated_normal: {data_dir_normal}\")\n",
    "\n",
    "# Create temporary structure for ImageFolder (it expects parent folder with subfolders)\n",
    "# We'll create a mapping manually\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    \"\"\"Custom ImageFolder that only loads specific folders\"\"\"\n",
    "    def __init__(self, abnormal_path, normal_path, transform=None):\n",
    "        # Create temporary root with only 2 folders\n",
    "        import tempfile\n",
    "        import shutil\n",
    "        \n",
    "        self.temp_dir = tempfile.mkdtemp()\n",
    "        temp_abnormal = os.path.join(self.temp_dir, 'abnormal')\n",
    "        temp_normal = os.path.join(self.temp_dir, 'normal')\n",
    "        \n",
    "        # Create symlinks to original folders\n",
    "        os.symlink(abnormal_path, temp_abnormal)\n",
    "        os.symlink(normal_path, temp_normal)\n",
    "        \n",
    "        # Initialize with temporary directory\n",
    "        super().__init__(self.temp_dir, transform=transform)\n",
    "    \n",
    "    def __del__(self):\n",
    "        # Clean up temp directory\n",
    "        import shutil\n",
    "        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):\n",
    "            shutil.rmtree(self.temp_dir)\n",
    "\n",
    "# Load datasets with rotated folders\n",
    "dataset_full_train = CustomImageFolder(data_dir_abnormal, data_dir_normal, transform=transformations_train)\n",
    "dataset_full_test = CustomImageFolder(data_dir_abnormal, data_dir_normal, transform=transformations_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded full_agreement dataset (rotated versions only):\")\n",
    "print(f\"   Total images: {len(dataset_full_train)}\")\n",
    "print(f\"   Classes: {dataset_full_train.classes}\")\n",
    "print(f\"   Class to index: {dataset_full_train.class_to_idx}\")\n",
    "\n",
    "# Count images per class\n",
    "abnormal_count = len([f for f in os.listdir(data_dir_abnormal) if f.endswith('.png')])\n",
    "normal_count = len([f for f in os.listdir(data_dir_normal) if f.endswith('.png')])\n",
    "print(f\"   rotated_abnormal: {abnormal_count} images\")\n",
    "print(f\"   rotated_normal: {normal_count} images\")\n",
    "\n",
    "# ========================================\n",
    "# K-FOLD CV SETUP\n",
    "# ========================================\n",
    "k = 5  # Number of folds for K-fold CV\n",
    "fold_sizes = foldSizes(dataset_full_train, k)\n",
    "\n",
    "print(f\"\\nüìä 5-Fold CV Setup:\")\n",
    "print(f\"   Fold sizes: {fold_sizes}\")\n",
    "\n",
    "# Getting train-test indices for all folds and repeats\n",
    "seeds = [42]  # 1 repeat only (changed from 3 repeats)\n",
    "train_test_idx_all = []\n",
    "\n",
    "# Generate indices for each seed and store them\n",
    "for seed in seeds:\n",
    "    train_test_idx_all = train_test_idx_all + allFoldsTrainTestIndices(seed, dataset_full_train, fold_sizes)\n",
    "\n",
    "print(f\"   Total runs: {len(train_test_idx_all)} (1 repeat √ó 5 folds)\")\n",
    "\n",
    "# ========================================\n",
    "# MODEL HYPERPARAMETERS\n",
    "# ========================================\n",
    "# [num_epochs, learning_rate, batch_size]\n",
    "hyperparameters_all = [\n",
    "    [100, 1e-4, 32],  # vgg16\n",
    "    [100, 1e-4, 32],  # vgg19\n",
    "    [100, 1e-4, 32],  # resnet\n",
    "    [100, 1e-4, 32]   # densenet\n",
    "]\n",
    "model_names = ['vgg16', 'vgg19', 'resnet', 'densenet']\n",
    "\n",
    "# ========================================\n",
    "# RESULTS STORAGE\n",
    "# ========================================\n",
    "base_save_path = './cv_results'\n",
    "os.makedirs(base_save_path, exist_ok=True)\n",
    "\n",
    "model_save_path = './model_temp.pth'  # Temporary model save location\n",
    "\n",
    "# Store path for prediction generation (needs to be the temp directory)\n",
    "data_dir_for_inference = dataset_full_train.root\n",
    "\n",
    "print(f\"\\nüíæ Results will be saved to: {base_save_path}\")\n",
    "\n",
    "# ========================================\n",
    "# TRAINING LOOP - Base Models\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING BASE MODEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üì¶ Training {model_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    metrics = []\n",
    "    model_hyperparameters = hyperparameters_all[model_names.index(model_name)]\n",
    "    \n",
    "    for idx, train_test_idx in enumerate(train_test_idx_all):\n",
    "        repeat_num = idx // k\n",
    "        fold_num = idx % k\n",
    "        \n",
    "        print(f\"\\n--- Repeat {repeat_num}, Fold {fold_num} ---\")\n",
    "        \n",
    "        # Create train/test subsets\n",
    "        real_train_idx = train_test_idx[0]\n",
    "        real_test_idx = train_test_idx[1]\n",
    "        \n",
    "        ds_train = Subset(dataset_full_train, real_train_idx)\n",
    "        ds_test = Subset(dataset_full_test, real_test_idx)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        sampler = getSampler(ds_train)\n",
    "        dl_train = DataLoader(ds_train, batch_size=model_hyperparameters[2], sampler=sampler)\n",
    "        dl_test = DataLoader(ds_test, batch_size=model_hyperparameters[2], shuffle=False)\n",
    "        \n",
    "        print(f\"Train samples: {len(ds_train)}, Test samples: {len(ds_test)}\")\n",
    "        \n",
    "        # Get and train model\n",
    "        model = getModel(model_name)\n",
    "        \n",
    "        best_acc, best_re, best_pr, best_f1 = trainBaseModel(\n",
    "            model=model,\n",
    "            num_epochs=model_hyperparameters[0],\n",
    "            learn_rate=model_hyperparameters[1],\n",
    "            dl_train=dl_train,\n",
    "            dl_test=dl_test,\n",
    "            model_save_path=model_save_path\n",
    "        )\n",
    "        \n",
    "        # Generate predictions - use the temp directory path\n",
    "        seed = seeds[repeat_num]\n",
    "        df_preds_train, df_preds_test = generateCNNPredictions(\n",
    "            data_path=data_dir_for_inference,\n",
    "            transformations=transformations_test,\n",
    "            train_test_idx=train_test_idx,\n",
    "            batch_size=model_hyperparameters[2],\n",
    "            seed=seed,\n",
    "            model_save_path=model_save_path\n",
    "        )\n",
    "        \n",
    "        # Save predictions\n",
    "        cv_config = {\"model\": model_name, \"repeat\": repeat_num, \"fold\": fold_num}\n",
    "        train_path, test_path = save_name_generator(cv_config, base_path=base_save_path)\n",
    "        \n",
    "        df_preds_train.to_csv(train_path, index=False)\n",
    "        df_preds_test.to_csv(test_path, index=False)\n",
    "        \n",
    "        metrics.append((best_acc, best_re, best_pr, best_f1))\n",
    "        \n",
    "        print(f\"‚úÖ Saved predictions to {os.path.dirname(train_path)}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    metrics = np.array(metrics)\n",
    "    \n",
    "    mean_acc = metrics[:, 0].mean()\n",
    "    std_acc = metrics[:, 0].std(ddof=1)\n",
    "    \n",
    "    mean_re = metrics[:, 1].mean()\n",
    "    std_re = metrics[:, 1].std(ddof=1)\n",
    "    \n",
    "    mean_pr = metrics[:, 2].mean()\n",
    "    std_pr = metrics[:, 2].std(ddof=1)\n",
    "    \n",
    "    mean_f1 = metrics[:, 3].mean()\n",
    "    std_f1 = metrics[:, 3].std(ddof=1)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä {model_name.upper()} - AVERAGE RESULTS (1x5-fold CV)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Accuracy : {mean_acc*100:.2f} ¬± {std_acc*100:.2f}%\")\n",
    "    print(f\"Recall   : {mean_re*100:.2f} ¬± {std_re*100:.2f}%\")\n",
    "    print(f\"Precision: {mean_pr*100:.2f} ¬± {std_pr*100:.2f}%\")\n",
    "    print(f\"F1-score : {mean_f1*100:.2f} ¬± {std_f1*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BASE MODEL TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crfOBNfWe-N6"
   },
   "source": [
    "## ***Meta-Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-14T13:53:00.692730Z",
     "iopub.status.idle": "2026-01-14T13:53:00.693084Z",
     "shell.execute_reply": "2026-01-14T13:53:00.692928Z",
     "shell.execute_reply.started": "2026-01-14T13:53:00.692907Z"
    },
    "id": "CYEa3lWcgQBp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Meta-classifier data preparation\n",
    "# Modified for 2 classes and local paths\n",
    "# =========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîß PREPARING META-CLASSIFIER INPUT DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Defining the path variables\n",
    "repeats = ['repeat_0/', 'repeat_1/', 'repeat_2/']\n",
    "folds = ['fold_0/', 'fold_1/', 'fold_2/', 'fold_3/', 'fold_4/']\n",
    "model_names = ['vgg16', 'vgg19', 'resnet', 'densenet']\n",
    "path_base = './cv_results/'\n",
    "\n",
    "# Expected column names for final meta-classifier input (2 classes)\n",
    "# 4 models √ó 2 class probabilities = 8 features\n",
    "col_names = (\n",
    "    ['labels'] +\n",
    "    [f'vgg16_{i}' for i in range(2)] +\n",
    "    [f'vgg19_{i}' for i in range(2)] +\n",
    "    [f'resnet_{i}' for i in range(2)] +\n",
    "    [f'densenet_{i}' for i in range(2)]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Iterating through each CV config\n",
    "# =========================\n",
    "\n",
    "for repeat in repeats:\n",
    "    for fold in folds:\n",
    "\n",
    "        train_list, test_list = [], []\n",
    "\n",
    "        # -------------------------\n",
    "        # Load and rename model predictions\n",
    "        # -------------------------\n",
    "        for model_name in model_names:\n",
    "\n",
    "            train_file = f\"{path_base}{repeat}{fold}{model_name}_train.csv\"\n",
    "            test_file = f\"{path_base}{repeat}{fold}{model_name}_test.csv\"\n",
    "\n",
    "            if not (os.path.exists(train_file) and os.path.exists(test_file)):\n",
    "                print(f\"‚ö†Ô∏è  Warning: Missing files for {model_name} in {repeat}{fold}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            df_train = pd.read_csv(train_file)\n",
    "            df_test = pd.read_csv(test_file)\n",
    "\n",
    "            # Rename probability columns to avoid collisions\n",
    "            prob_cols = [c for c in df_train.columns if c != 'labels']\n",
    "\n",
    "            df_train = df_train.rename(\n",
    "                columns={c: f\"{model_name}_{c}\" for c in prob_cols}\n",
    "            )\n",
    "            df_test = df_test.rename(\n",
    "                columns={c: f\"{model_name}_{c}\" for c in prob_cols}\n",
    "            )\n",
    "\n",
    "            train_list.append(df_train)\n",
    "            test_list.append(df_test)\n",
    "\n",
    "        # Skip if no data loaded\n",
    "        if len(train_list) == 0 or len(test_list) == 0:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {repeat}{fold} due to missing files.\")\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # Merge predictions from different models\n",
    "        # -------------------------\n",
    "        mc_train = train_list[0]\n",
    "        mc_test = test_list[0]\n",
    "\n",
    "        for i in range(1, len(train_list)):\n",
    "            mc_train = mc_train.merge(\n",
    "                train_list[i].drop(columns=['labels']),\n",
    "                left_index=True,\n",
    "                right_index=True\n",
    "            )\n",
    "            mc_test = mc_test.merge(\n",
    "                test_list[i].drop(columns=['labels']),\n",
    "                left_index=True,\n",
    "                right_index=True\n",
    "            )\n",
    "\n",
    "        # -------------------------\n",
    "        # Final sanity checks\n",
    "        # -------------------------\n",
    "        assert mc_train.shape[1] == len(col_names), \\\n",
    "            f\"Column mismatch in train: {mc_train.shape[1]} vs {len(col_names)}\"\n",
    "        assert mc_test.shape[1] == len(col_names), \\\n",
    "            f\"Column mismatch in test: {mc_test.shape[1]} vs {len(col_names)}\"\n",
    "\n",
    "        # -------------------------\n",
    "        # Assign final column names\n",
    "        # -------------------------\n",
    "        mc_train.columns = col_names\n",
    "        mc_test.columns = col_names\n",
    "\n",
    "        # -------------------------\n",
    "        # Save final meta-classifier inputs\n",
    "        # -------------------------\n",
    "        mc_train.to_csv(f\"{path_base}{repeat}{fold}mc_train_inputs.csv\", index=False)\n",
    "        mc_test.to_csv(f\"{path_base}{repeat}{fold}mc_test_inputs.csv\", index=False)\n",
    "\n",
    "        print(f\"‚úÖ Saved meta-classifier inputs for {repeat}{fold}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ META-CLASSIFIER DATA PREPARATION COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-14T13:53:00.694238Z",
     "iopub.status.idle": "2026-01-14T13:53:00.694499Z",
     "shell.execute_reply": "2026-01-14T13:53:00.694398Z",
     "shell.execute_reply.started": "2026-01-14T13:53:00.694383Z"
    },
    "id": "3_tP_Yh8chKp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training the meta-classifier\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING META-CLASSIFIER TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Defining path variables\n",
    "repeats = ['repeat_0/', 'repeat_1/', 'repeat_2/']\n",
    "folds = ['fold_0/', 'fold_1/', 'fold_2/', 'fold_3/', 'fold_4/']\n",
    "path_base = './cv_results/'\n",
    "model_save_path = './model_temp.pth'\n",
    "\n",
    "# Meta-classifier hyperparameters\n",
    "num_epochs, learn_rate, batch_size, momentum, weight_decay = 200, 7.801e-2, 47, 0.9855, 5.526e-2\n",
    "\n",
    "# Training the meta-classifier\n",
    "for repeat in repeats:\n",
    "    for fold in folds:\n",
    "        print(f\"\\n--- {repeat}{fold} ---\")\n",
    "        \n",
    "        # Check if input files exist\n",
    "        train_input_path = path_base + repeat + fold + 'mc_train_inputs.csv'\n",
    "        test_input_path = path_base + repeat + fold + 'mc_test_inputs.csv'\n",
    "        \n",
    "        if not (os.path.exists(train_input_path) and os.path.exists(test_input_path)):\n",
    "            print(f\"‚ö†Ô∏è  Skipping {repeat}{fold} - input files not found\")\n",
    "            continue\n",
    "        \n",
    "        # Load data and convert to tensor dataset\n",
    "        ds_train = MyDataset(train_input_path)\n",
    "        ds_test = MyDataset(test_input_path)\n",
    "        \n",
    "        # Define dataloaders\n",
    "        dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "        dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Define the model\n",
    "        model = metaClassifier()\n",
    "\n",
    "        # Training\n",
    "        best_acc, best_re, best_pr, best_f1 = trainMetaClassifier(\n",
    "            model=model,\n",
    "            num_epochs=num_epochs,\n",
    "            learn_rate=learn_rate,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay,\n",
    "            dl_train=dl_train,\n",
    "            dl_test=dl_test,\n",
    "            model_save_path=model_save_path\n",
    "        )\n",
    "\n",
    "        # Generate predictions\n",
    "        df_preds_train, df_preds_test = generateMCPredictions(\n",
    "            dl_train=dl_train,\n",
    "            dl_test=dl_test,\n",
    "            batch_size=batch_size,\n",
    "            model_save_path=model_save_path\n",
    "        )\n",
    "        \n",
    "        # Saving predictions\n",
    "        train_path = path_base + repeat + fold + 'mc_train_outputs.csv'\n",
    "        test_path = path_base + repeat + fold + 'mc_test_outputs.csv'\n",
    "        df_preds_train.to_csv(train_path, index=False)\n",
    "        df_preds_test.to_csv(test_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Saved predictions to {os.path.dirname(train_path)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ META-CLASSIFIER TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-14T13:53:00.695162Z",
     "iopub.status.idle": "2026-01-14T13:53:00.695442Z",
     "shell.execute_reply": "2026-01-14T13:53:00.695309Z",
     "shell.execute_reply.started": "2026-01-14T13:53:00.695294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä EVALUATING META-CLASSIFIER PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_model_metrics_train = []\n",
    "all_model_metrics_test  = []\n",
    "\n",
    "repeats = ['repeat_0/', 'repeat_1/', 'repeat_2/']\n",
    "folds   = ['fold_0/', 'fold_1/', 'fold_2/', 'fold_3/', 'fold_4/']\n",
    "path_base = './cv_results/'\n",
    "\n",
    "for r in repeats:\n",
    "    for k in folds:\n",
    "        \n",
    "        train_output_path = path_base + r + k + 'mc_train_outputs.csv'\n",
    "        test_output_path = path_base + r + k + 'mc_test_outputs.csv'\n",
    "        \n",
    "        if not (os.path.exists(train_output_path) and os.path.exists(test_output_path)):\n",
    "            print(f\"‚ö†Ô∏è  Skipping {r}{k} - output files not found\")\n",
    "            continue\n",
    "\n",
    "        mc_data_train = pd.read_csv(train_output_path)\n",
    "        mc_data_test  = pd.read_csv(test_output_path)\n",
    "\n",
    "        y_train = mc_data_train[\"labels\"]\n",
    "        y_test  = mc_data_test[\"labels\"]\n",
    "\n",
    "        # Argmax over class probabilities\n",
    "        y_pred_train = mc_data_train.iloc[:, 1:].idxmax(axis=1).astype(int)\n",
    "        y_pred_test  = mc_data_test.iloc[:, 1:].idxmax(axis=1).astype(int)\n",
    "\n",
    "        # Train metrics\n",
    "        all_model_metrics_train.append([\n",
    "            f1_score(y_train, y_pred_train, average=\"macro\"),\n",
    "            recall_score(y_train, y_pred_train, average=\"macro\"),\n",
    "            precision_score(y_train, y_pred_train, average=\"macro\"),\n",
    "            accuracy_score(y_train, y_pred_train)\n",
    "        ])\n",
    "\n",
    "        # Test metrics\n",
    "        all_model_metrics_test.append([\n",
    "            f1_score(y_test, y_pred_test, average=\"macro\"),\n",
    "            recall_score(y_test, y_pred_test, average=\"macro\"),\n",
    "            precision_score(y_test, y_pred_test, average=\"macro\"),\n",
    "            accuracy_score(y_test, y_pred_test)\n",
    "        ])\n",
    "        \n",
    "        print(f\"‚úÖ Evaluated {r}{k}\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "col_names = ['f1-score', 'recall', 'precision', 'accuracy']\n",
    "\n",
    "df_train = pd.DataFrame(all_model_metrics_train, columns=col_names)\n",
    "df_test  = pd.DataFrame(all_model_metrics_test,  columns=col_names)\n",
    "\n",
    "# Mean ¬± std (sample std)\n",
    "mean_train = df_train.mean()\n",
    "std_train  = df_train.std(ddof=1)\n",
    "\n",
    "mean_test = df_test.mean()\n",
    "std_test  = df_test.std(ddof=1)\n",
    "\n",
    "# Format as percentages\n",
    "avg_metrics_train = pd.DataFrame({\n",
    "    col: [f\"{mean_train[col]*100:.2f} ¬± {std_train[col]*100:.2f}\"]\n",
    "    for col in col_names\n",
    "})\n",
    "\n",
    "avg_metrics_test = pd.DataFrame({\n",
    "    col: [f\"{mean_test[col]*100:.2f} ¬± {std_test[col]*100:.2f}\"]\n",
    "    for col in col_names\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà FINAL RESULTS - META-CLASSIFIER (3x5-fold CV)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüîµ Train Set (mean ¬± std, %):\")\n",
    "display(avg_metrics_train)\n",
    "\n",
    "print(\"\\nüî¥ Test Set (mean ¬± std, %):\")\n",
    "display(avg_metrics_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EVALUATION COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8855135,
     "sourceId": 14415336,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
